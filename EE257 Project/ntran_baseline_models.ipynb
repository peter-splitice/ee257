{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE257 Project - Feature Extraction\n",
    "\n",
    "[Shoulder Implant X-Ray Manufacturer Classification Data Set (2020)](https://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+X-Ray+Manufacturer+Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tickn\\\\ml\\\\EE257\\\\EE257 Project\\\\dataset'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "dataset_path = current_path + '\\dataset'\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 597 files belonging to 4 classes.\n",
      "Using 478 files for training.\n",
      "Found 597 files belonging to 4 classes.\n",
      "Using 119 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(dataset_path + '\\data')\n",
    "batch_size = 32\n",
    "\n",
    "def describe_img(filepath):\n",
    "    rand_img = random.choice(list(filepath.glob('**\\*.jpg')))\n",
    "    width, height = Image.open(str(rand_img)).size\n",
    "\n",
    "    return width, height\n",
    "\n",
    "img_width, img_height = describe_img(data_dir)\n",
    "\n",
    "# load image dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 62500)\n",
      "(478,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dataset_to_2D(dataset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for img_batch, label_batch in dataset:\n",
    "        # flatten images since model fit() needs 2D input\n",
    "        for img in img_batch:\n",
    "            x.append(img.flatten())\n",
    "        for label in label_batch:\n",
    "            y.append(label)\n",
    "    return x, y\n",
    "        \n",
    "x_train, y_train = dataset_to_2D(train_ds.as_numpy_iterator())\n",
    "x_test, y_test = dataset_to_2D(test_ds.as_numpy_iterator())\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 -- Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg',max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='newton-cg')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 5  8  2  0]\n",
      " [ 1 36  8 16]\n",
      " [ 1  4  3 10]\n",
      " [ 3 12  2  8]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.50      0.33      0.40        15\n",
      "       Depuy       0.60      0.59      0.60        61\n",
      "     Tornier       0.20      0.17      0.18        18\n",
      "      Zimmer       0.24      0.32      0.27        25\n",
      "\n",
      "    accuracy                           0.44       119\n",
      "   macro avg       0.38      0.35      0.36       119\n",
      "weighted avg       0.45      0.44      0.44       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logreg_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, logreg_pred))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, logreg_pred, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.436975 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %model.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 8  4  2  1]\n",
      " [ 7 41  2 11]\n",
      " [ 1  6  2  9]\n",
      " [ 2 11  2 10]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.44      0.53      0.48        15\n",
      "       Depuy       0.66      0.67      0.67        61\n",
      "     Tornier       0.25      0.11      0.15        18\n",
      "      Zimmer       0.32      0.40      0.36        25\n",
      "\n",
      "    accuracy                           0.51       119\n",
      "   macro avg       0.42      0.43      0.42       119\n",
      "weighted avg       0.50      0.51      0.50       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_predict = tree.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, tree_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, tree_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.512605 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %tree.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %tree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 8  4  1  2]\n",
      " [ 4 40  3 14]\n",
      " [ 3  7  1  7]\n",
      " [ 4 12  1  8]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.42      0.53      0.47        15\n",
      "       Depuy       0.63      0.66      0.65        61\n",
      "     Tornier       0.17      0.06      0.08        18\n",
      "      Zimmer       0.26      0.32      0.29        25\n",
      "\n",
      "    accuracy                           0.48       119\n",
      "   macro avg       0.37      0.39      0.37       119\n",
      "weighted avg       0.46      0.48      0.46       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=100)\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "svm_predict = svm.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, svm_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, svm_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 1.000000 \n",
      " Test error: 0.478992 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %svm.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 7  6  1  1]\n",
      " [ 2 41  4 14]\n",
      " [ 0 10  1  7]\n",
      " [ 3 13  4  5]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.58      0.47      0.52        15\n",
      "       Depuy       0.59      0.67      0.63        61\n",
      "     Tornier       0.10      0.06      0.07        18\n",
      "      Zimmer       0.19      0.20      0.19        25\n",
      "\n",
      "    accuracy                           0.45       119\n",
      "   macro avg       0.36      0.35      0.35       119\n",
      "weighted avg       0.43      0.45      0.44       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model  -- LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "\n",
    "lda_predict = lda.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, lda_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, lda_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error: 0.887029 \n",
      " Test error: 0.453782 \n"
     ]
    }
   ],
   "source": [
    "print(\" Training error: %f \" %lda.score(x_train, y_train))\n",
    "print(\" Test error: %f \" %lda.score(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b98948d77b2674b121e07fa87853bc8fb999bdfd9d3945db432cae405ad87eae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

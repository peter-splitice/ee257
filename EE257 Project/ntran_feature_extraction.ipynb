{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE257 Project - Feature Extraction\n",
    "\n",
    "[Shoulder Implant X-Ray Manufacturer Classification Data Set (2020)](https://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+X-Ray+Manufacturer+Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tickn\\\\ml\\\\EE257\\\\EE257 Project\\\\dataset'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "dataset_path = current_path + '\\dataset'\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 597 files belonging to 4 classes.\n",
      "Using 478 files for training.\n",
      "Found 597 files belonging to 4 classes.\n",
      "Using 119 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split\n",
    "\n",
    "data_dir = pathlib.Path(dataset_path + '\\data')\n",
    "batch_size = 32\n",
    "\n",
    "def describe_img(filepath):\n",
    "    rand_img = random.choice(list(filepath.glob('**\\*.jpg')))\n",
    "    width, height = Image.open(str(rand_img)).size\n",
    "\n",
    "    return width, height\n",
    "\n",
    "def random_img(filepath):\n",
    "    return  random.choice(list(filepath.glob('**\\*.jpg')))\n",
    "\n",
    "img_width, img_height = describe_img(data_dir)\n",
    "\n",
    "# load image dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size = (img_height , img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 62500)\n",
      "(478,)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_2D(dataset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for img_batch, label_batch in dataset:\n",
    "        # flatten images since model fit() needs 2D input\n",
    "        for img in img_batch:\n",
    "            x.append(img.flatten())\n",
    "        for label in label_batch:\n",
    "            y.append(label)\n",
    "    return x, y\n",
    "        \n",
    "x_train, y_train = dataset_to_2D(train_ds.as_numpy_iterator())\n",
    "x_test, y_test = dataset_to_2D(test_ds.as_numpy_iterator())\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(max_iter=10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection pipeline\n",
    "lasso = Lasso(fit_intercept=True, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   53   606  1106  1377  1693  1876  2932  3841  3953  5048  5381  6546\n",
      "  7571  8106  8453  8697  8698  8884  9089  9358  9367  9608  9629  9856\n",
      " 10203 10547 10613 10615 10880 10953 11096 11436 11857 11908 12192 12214\n",
      " 12366 12373 12389 12616 12640 12652 12853 12867 12910 14104 14147 14781\n",
      " 15454 15614 16091 16137 16138 16562 16601 16623 16696 17437 17582 17965\n",
      " 18892 18951 19394 19446 19696 20794 21089 21123 21671 21682 21684 22158\n",
      " 22531 22817 23108 24116 25175 25454 25750 27335 27567 27580 27627 27875\n",
      " 28156 28667 28918 29525 29954 30417 30676 31045 31134 31385 31655 32051\n",
      " 32126 32299 32594 32871 36437 36902 36931 38171 38929 39428 39429 40175\n",
      " 40231 40301 41337 42312 42814 43275 43327 43426 43525 43587 44570 46619\n",
      " 47830 47831 48294 48408 48438 48439 48440 48457 48824 48999 49249 49757\n",
      " 50167 50250 50531 50824 50934 50935 51269 51349 51375 51770 52500 52525\n",
      " 52537 52553 52787 53287 54327 54688 54998 55580 55830 56209 56210 56222\n",
      " 56652 56750 56775 56798 56803 56805 56953 57558 57573 57701 57735 57922\n",
      " 59312 59702 60187 60981 61056 62433 62437 62451]\n"
     ]
    }
   ],
   "source": [
    "# feature selection using Lasso shrinkage\n",
    "l1_select = SelectFromModel(lasso).fit(x_train, y_train)\n",
    "print(l1_select.get_support(indices=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(max_iter=10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(fit_intercept=True, max_iter=10000)\n",
    "ridge.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    6    22    23 ... 62490 62491 62492]\n"
     ]
    }
   ],
   "source": [
    "# feature selection using Ridge shrinkage\n",
    "l2_select = SelectFromModel(ridge).fit(x_train, y_train)\n",
    "print(l2_select.get_support(indices=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         'kernel': ['linear', 'poly', 'rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search best param for baseline model\n",
    "svm = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid={\n",
    "        \"C\" : [0.1 , 1.0 , 10.0 , 100.0 , 1000.0],\n",
    "        \"kernel\" : ['linear' , 'poly' , 'rbf']\n",
    "    },\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "svm.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error with l1 reg: 0.953975 \n",
      " Test error l1 reg: 0.478992 \n",
      " Training error l2 reg: 0.951883 \n",
      " Test error l2 reg: 0.504202 \n"
     ]
    }
   ],
   "source": [
    "clf1 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Ridge(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , SVC(C=10.0 , kernel='rbf'))\n",
    "])\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Lasso(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , SVC(C=10.0 , kernel='rbf'))\n",
    "])\n",
    "\n",
    "\n",
    "clf1.fit(x_train , y_train)\n",
    "clf2.fit(x_train,y_train)\n",
    "\n",
    "print(\" Training error with l1 reg: %f \" %clf1.score(x_train, y_train))\n",
    "print(\" Test error l1 reg: %f \" %clf1.score(x_test, y_test))\n",
    "print()\n",
    "print(\" Training error l2 reg: %f \" %clf2.score(x_train, y_train))\n",
    "print(\" Test error l2 reg: %f \" %clf2.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 5  7  1  2]\n",
      " [ 3 45  1 12]\n",
      " [ 2 10  0  6]\n",
      " [ 4 13  1  7]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.36      0.33      0.34        15\n",
      "       Depuy       0.60      0.74      0.66        61\n",
      "     Tornier       0.00      0.00      0.00        18\n",
      "      Zimmer       0.26      0.28      0.27        25\n",
      "\n",
      "    accuracy                           0.48       119\n",
      "   macro avg       0.30      0.34      0.32       119\n",
      "weighted avg       0.41      0.48      0.44       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl1_predict = clf1.predict(x_test)\n",
    "cl2_predict = clf2.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, cl1_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, cl1_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[ 5  6  1  3]\n",
      " [ 1 48  4  8]\n",
      " [ 0 12  1  5]\n",
      " [ 4 14  1  6]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cofield       0.50      0.33      0.40        15\n",
      "       Depuy       0.60      0.79      0.68        61\n",
      "     Tornier       0.14      0.06      0.08        18\n",
      "      Zimmer       0.27      0.24      0.26        25\n",
      "\n",
      "    accuracy                           0.50       119\n",
      "   macro avg       0.38      0.35      0.35       119\n",
      "weighted avg       0.45      0.50      0.47       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, cl2_predict))\n",
    "print(\"--------------------------\")\n",
    "print(classification_report(y_test, cl2_predict, target_names=['Cofield' , 'Depuy' , 'Tornier' , 'Zimmer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "d_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    param_grid={\n",
    "        \"criterion\" : ['gini' , 'entropy'],\n",
    "        \"splitter\" : ['best' , 'random']\n",
    "    },\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "d_tree.fit(x_train , y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'splitter': 'best'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error with l1 reg: 1.000000 \n",
      " Test error l1 reg: 0.369748 \n",
      "\n",
      " Training error l2 reg: 1.000000 \n",
      " Test error l2 reg: 0.378151 \n"
     ]
    }
   ],
   "source": [
    "clf3 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Ridge(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , DecisionTreeClassifier(criterion=\"entropy\"))\n",
    "])\n",
    "\n",
    "clf4 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Lasso(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , DecisionTreeClassifier(criterion=\"entropy\"))\n",
    "])\n",
    "\n",
    "\n",
    "clf3.fit(x_train , y_train)\n",
    "clf4.fit(x_train,y_train)\n",
    "\n",
    "print(\" Training error with l1 reg: %f \" %clf3.score(x_train, y_train))\n",
    "print(\" Test error l1 reg: %f \" %clf3.score(x_test, y_test))\n",
    "print()\n",
    "print(\" Training error l2 reg: %f \" %clf4.score(x_train, y_train))\n",
    "print(\" Test error l2 reg: %f \" %clf4.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [1, 100, 1000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tree = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid={\n",
    "        \"n_estimators\" : [1 , 100 , 1000],\n",
    "        \"criterion\" : ['gini' , 'entropy'],\n",
    "    },\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "rand_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 100}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training error with l1 reg: 1.000000 \n",
      " Test error l1 reg: 0.521008 \n",
      "\n",
      " Training error l2 reg: 1.000000 \n",
      " Test error l2 reg: 0.512605 \n"
     ]
    }
   ],
   "source": [
    "clf5 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Ridge(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf6 = Pipeline([\n",
    "    ('feature selection' , SelectFromModel(Lasso(fit_intercept=True, max_iter=10000))),\n",
    "    ('model' , RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "clf5.fit(x_train , y_train)\n",
    "clf6.fit(x_train,y_train)\n",
    "\n",
    "print(\" Training error with l1 reg: %f \" %clf5.score(x_train, y_train))\n",
    "print(\" Test error l1 reg: %f \" %clf5.score(x_test, y_test))\n",
    "print()\n",
    "print(\" Training error l2 reg: %f \" %clf6.score(x_train, y_train))\n",
    "print(\" Test error l2 reg: %f \" %clf6.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6945c16a0984d1ac9e5b0055ebd9257e73620e552f2c1a12e2e737359eca363"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
